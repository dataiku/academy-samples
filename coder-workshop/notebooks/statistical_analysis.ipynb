{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Statistical analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Univariate analysis is perhaps the simplest form of statistical analysis. The key fact is that only one variable is involved.\n",
        "\n",
        "<center><strong>Select Cell > Run All to execute the whole analysis</strong></center>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setup and dataset loading <a id=\"setup\" /> \n",
        "\n",
        "First of all, let's load the libraries that we'll use"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%pylab inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import dataiku                               # Access to Dataiku datasets\n",
        "import pandas as pd, numpy as np             # Data manipulation \n",
        "from matplotlib import pyplot as plt         # Graphing\n",
        "import seaborn as sns                        # Graphing\n",
        "import warnings                              # Disable some warnings\n",
        "warnings.filterwarnings(\"ignore\",category=DeprecationWarning)\n",
        "from scipy import stats                      # Stats"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The first thing we do is now to load the dataset and put aside the three main types of columns:\n",
        "\n",
        "* Numerics\n",
        "* Categorical\n",
        "* Dates\n",
        "\n",
        "Statistical analysis requires having the data in memory, we are only going to load a sample of the data. Modify the following cell to change the size of the sample."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "dataset_limit = 10000"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Load a DSS dataset as a Pandas dataframe. ***UPDATE LINE 3 WITH THE NAME OF YOUR DATASET***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: UPDATE LINE 3 WITH THE NAME OF YOUR DATASET\n",
        "# Take a handle on the dataset\n",
        "mydataset = dataiku.Dataset(\"dataset_name\")\n",
        "\n",
        "# Load the first lines.\n",
        "# You can also load random samples, limit yourself to some columns, or only load\n",
        "# data matching some filters.\n",
        "#\n",
        "# Please refer to the Dataiku Python API documentation for more information\n",
        "df = mydataset.get_dataframe(limit = dataset_limit)\n",
        "\n",
        "df_orig = df.copy()\n",
        "\n",
        "# Get the column names\n",
        "numerical_columns = list(df.select_dtypes(include=[np.number]).columns)\n",
        "categorical_columns = list(df.select_dtypes(include=[object]).columns)\n",
        "date_columns = list(df.select_dtypes(include=['<M8[ns]']).columns)\n",
        "\n",
        "# Print a quick summary of what we just loaded\n",
        "print(\"Loaded dataset\")\n",
        "print(\"   Rows: %s\" % df.shape[0])\n",
        "print(\"   Columns: %s (%s num, %s cat, %s date)\" % (df.shape[1], \n",
        "                                                    len(numerical_columns), len(categorical_columns),\n",
        "                                                    len(date_columns)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Preprocessing of the data <a id=\"preprocessing\" />"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "***UPDATE `value_col` WITH THE NAME OF YOUR COLUMN OF INTEREST***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "value_col = 'COLUMN_OF_INTEREST'\n",
        "print(\"Selected value column is '%s'\" % (value_col))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We drop rows for which `value_col` is missing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df.dropna(subset=[value_col], inplace=True)\n",
        "df_pop_1 = df[value_col]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Statistical analysis and vizualisation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### General statistics\n",
        "Number of records, mean, standard deviation, minimal value, quartiles, maximum value, mode, variance, skewness and kurtosis."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "additional_stats = [\"var\", \"skew\", \"kurtosis\"]\n",
        "print(\"Stats about your series:\\n\", df_pop_1.describe().append(pd.Series(NaN if df_pop_1.mode().empty else df_pop_1.mode()[0], index=[\"mode\"])).append(pd.Series([df_pop_1.__getattr__(x)() for x in additional_stats], index=additional_stats)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Histogram\n",
        "Histograms let you see the number of occurrences in your value column."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.title(\"Histogram of \"+value_col);\n",
        "plt.hist(df_pop_1);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Distplot\n",
        "Distplots combine an histogram with a kernel density estimation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "sns.distplot(df_pop_1);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Box plot"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "A simple way of representing statistical data on a plot in which a rectangle is drawn to represent the second and third quartiles, with a vertical line inside to indicate the median value. The lower and upper quartiles are shown as horizontal lines either side of the rectangle."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "sns.boxplot(df_pop_1);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Violin plot"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The violin plot is similar to box plots, except that they also show the probability density of the data at different values. Violin plots include a marker for the median of the data and a box indicating the interquartile range, as in standard box plots. Overlaid on this box plot is a kernel density estimation. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "sns.violinplot(df_pop_1);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Letter value plot"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Letter value plots are an improvement upon boxplots for large datasets.\n",
        "\n",
        "They display the median and the quartiles, like a standard box plot, but will also draw boxes for subsequent \"eights\", \"sixteenth\" etc... which are generically called letter values.\n",
        "\n",
        "A cut off condition will leave a reasonable number of outliers out of the final boxes, helping you spot them easily.\n",
        "\n",
        "Letter value plots give a good sense of the distribution of data, and of its skewness."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "sns.boxenplot(df_pop_1);"
      ]
    }
  ],
  "metadata": {
    "createdOn": 1617634652885,
    "creator": "msakande",
    "customFields": {},
    "hide_input": false,
    "kernelspec": {
      "display_name": "Python 3.9.10 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.10"
    },
    "modifiedBy": "admin",
    "tags": [],
    "vscode": {
      "interpreter": {
        "hash": "ac2eaa0ea0ebeafcc7822e65e46aa9d4f966f30b695406963e145ea4a91cd4fc"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}
